#!/usr/bin/env python3
"""
ç®€å•çš„ä»£ç æµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯å¤šæ¨¡æ€ReIDä»£ç çš„æ­£ç¡®æ€§
"""

import os
import sys
import torch
import numpy as np

def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¿…è¦çš„å¯¼å…¥"""
    print("Testing imports...")
    
    try:
        from datasets import build_dataloader
        print("âœ“ datasets.build_dataloader imported successfully")
    except ImportError as e:
        print(f"âœ— Failed to import datasets.build_dataloader: {e}")
        return False
    
    try:
        from model import build_model
        print("âœ“ model.build_model imported successfully")
    except ImportError as e:
        print(f"âœ— Failed to import model.build_model: {e}")
        return False
    
    try:
        from utils.multimodal_evaluator import MultiModalEvaluator
        print("âœ“ MultiModalEvaluator imported successfully")
    except ImportError as e:
        print(f"âœ— Failed to import MultiModalEvaluator: {e}")
        return False
    
    try:
        from processor.processor import do_inference
        print("âœ“ do_inference imported successfully")
    except ImportError as e:
        print(f"âœ— Failed to import do_inference: {e}")
        return False
    
    return True

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\nTesting model creation...")
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿå‚æ•°
        class MockArgs:
            def __init__(self):
                self.dataset_name = 'PRCV'
                self.pretrain_choice = 'ViT-B/32'
                self.img_size = [384, 128]
                self.stride_size = [32, 32]
                self.temperature = 0.07
                self.fusion_way = 'concat'
                self.loss_names = 'itc+id'
        
        args = MockArgs()
        
        # æµ‹è¯•æ¨¡å‹æ„å»º
        from model import build_model
        model = build_model(args, num_classes=100)
        print("âœ“ Model created successfully")
        print(f"  Model type: {type(model).__name__}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 2
        mock_batch = {
            'vis_images': torch.randn(batch_size, 3, 384, 128),
            'nir_images': torch.randn(batch_size, 3, 384, 128),
            'cp_images': torch.randn(batch_size, 3, 384, 128),
            'sk_images': torch.randn(batch_size, 3, 384, 128),
            'caption_ids': torch.randint(0, 1000, (batch_size, 77)),
            'pids': torch.randint(0, 100, (batch_size,))
        }
        
        with torch.no_grad():
            output = model(mock_batch)
            print("âœ“ Forward pass successful")
            print(f"  Output keys: {list(output.keys())}")
        
        return True
        
    except Exception as e:
        print(f"âœ— Model creation failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dataset_structure():
    """æµ‹è¯•æ•°æ®é›†ç»“æ„"""
    print("\nTesting dataset structure...")
    
    try:
        # æ£€æŸ¥PRCVæ•°æ®é›†ç±»
        from datasets.prcv import PRCV
        print("âœ“ PRCV dataset class imported successfully")
        
        # æ£€æŸ¥å¤šæ¨¡æ€æ•°æ®é›†ç±»
        from datasets.bases import MultiModalDataset, MultiModalQueryDataset
        print("âœ“ MultiModalDataset and MultiModalQueryDataset imported successfully")
        
        return True
        
    except Exception as e:
        print(f"âœ— Dataset structure test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_evaluator():
    """æµ‹è¯•è¯„ä¼°å™¨"""
    print("\nTesting evaluator...")
    
    try:
        from utils.multimodal_evaluator import MultiModalEvaluator
        
        # åˆ›å»ºæ¨¡æ‹Ÿå‚æ•°å’Œæ•°æ®åŠ è½½å™¨
        class MockArgs:
            def __init__(self):
                self.dataset_name = 'PRCV'
        
        class MockDataLoader:
            def __iter__(self):
                return iter([])
        
        args = MockArgs()
        gallery_loader = MockDataLoader()
        query_loader = MockDataLoader()
        
        evaluator = MultiModalEvaluator(args, gallery_loader, query_loader)
        print("âœ“ MultiModalEvaluator created successfully")
        
        return True
        
    except Exception as e:
        print(f"âœ— Evaluator test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 50)
    print("Multi-Modal ReID Code Test")
    print("=" * 50)
    
    tests = [
        test_imports,
        test_model_creation,
        test_dataset_structure,
        test_evaluator
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
            else:
                print(f"âœ— {test.__name__} failed")
        except Exception as e:
            print(f"âœ— {test.__name__} failed with exception: {e}")
    
    print("\n" + "=" * 50)
    print(f"Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ All tests passed! Code is ready to use.")
        return True
    else:
        print("âŒ Some tests failed. Please check the errors above.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
